# NEXUSFLOW | AI Development Agency Terminal

NexusFlow is a local-first, terminal-style interface that orchestrates a team of specialized AI agents to build software. It mimics a professional development environment with role-based agents (Architect, Coder, QA, Security), a virtual file system, and integrated telemetry.

![Uploading Screenshot 2025-11-23 040048.png‚Ä¶]()


## üöÄ Features

- **Multi-Agent Orchestration**: 8 specialized AI personas (Chat, Plan, Architect, Coder, Test, Secure, Deploy, Monitor).
- **Dual Backend Support**:
  - **Google Gemini**: High-performance cloud inference.
  - **Ollama**: Fully local, private inference (requires Ollama installed).
- **Configuration Autosave**: Your settings are automatically saved and remembered when you close and reopen the application.
- **VSCode Bridge**: A simulated IDE environment to visualize project structure, Git commits, and code generated by agents.
- **RAG Engine**: Drag-and-drop context loading for documents.
- **System Telemetry**: Real-time visualization of CPU, Memory, and Network simulation.
- **Cyberpunk/Sci-Fi UI**: CRT scanlines, retro fonts, and immersive animations.

## ‚ö° Quickstart (Vite)

This project uses **Vite** instead of Create React App to ensure fast startup and zero vulnerabilities.

### 1. Prerequisites
- **Node.js** (v18+)
- **Ollama** (optional, for local AI)

### 2. Setup Project
Create a folder and install dependencies:

```bash
# 1. Create project folder
mkdir nexusflow
cd nexusflow

# 2. Initialize package.json
npm init -y

# 3. Install dependencies
npm install react react-dom lucide-react recharts @google/genai

# 4. Install Dev dependencies (Vite + TypeScript)
npm install -D vite @vitejs/plugin-react typescript @types/react @types/react-dom autoprefixer postcss tailwindcss
```

### 3. Verify Dependencies
Before running the application, verify all dependencies are properly installed:

```bash
npm run check-deps
```

This will run the dependency verification tool to ensure everything is properly set up.

**Note**: When using Ollama as your AI provider, the application will automatically verify Ollama connectivity and required models during startup. If issues are detected, the app will display clear error messages with actionable steps to resolve them.

### 4. Configure Vite
Ensure `vite.config.ts` exists in the root:
```ts
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
})
```

### 5. Run the App
```bash
npx vite
```
Open `http://localhost:5173`.

---

## ü§ñ Connecting Local AI (Ollama)

To use NexusFlow with a local model (e.g., Llama 3), you must configure Ollama to allow browser requests.

### Step 1: Install a Model
```bash
ollama pull llama3
```

### Step 2: Configure CORS (Crucial!)
By default, browsers block websites from talking to local servers. You must enable CORS.

**Mac / Linux:**
```bash
launchctl setenv OLLAMA_ORIGINS "*"
# Restart the Ollama app completely after running this
```

**Windows:**
1. Quit Ollama from the taskbar (Right-click icon -> Quit).
2. Open **Environment Variables** (search in Start menu).
3. Under **System variables**, click **New**.
   - Name: `OLLAMA_ORIGINS`
   - Value: `*`
4. Click OK, then **Start Ollama** again.
### Step 3: Test Connection
1. Open NexusFlow Settings (Gear Icon).
2. Go to **Backend Services**.
3. Select **OLLAMA LOCAL**.
4. Click **[ TEST CONNECTION ]**.

### Automatic Startup Validation
When you start NexusFlow with Ollama enabled, the application will automatically:

- ‚úÖ Check if Ollama service is running
- ‚úÖ Verify required AI models are downloaded
- ‚úÖ Validate network connectivity

If any issues are detected, you'll see clear error messages with actionable steps to resolve them.

### Troubleshooting Common Issues

**"Cannot connect to Ollama" Error:**
- Ensure Ollama is running: `ollama serve`
- Check that `OLLAMA_ORIGINS="*"` environment variable is set
- Restart Ollama after changing environment variables
- Verify the URL in settings: default is `http://localhost:11434`

**"Model not found" Error:**
- Pull the required models: `ollama pull llama3`
- For coding tasks: `ollama pull llama3` (or your preferred coding model)
- Check available models: `ollama list`

**Connection blocked by CORS:**
- Set environment variable: `OLLAMA_ORIGINS="*"`
- Restart Ollama completely after setting the variable
- Clear browser cache if issues persist

---

## üõ†Ô∏è Troubleshooting

## üìù Agent Commands

| Command | Agent | Role |
|---------|-------|------|
| `/chat` | **NEXUS-CHAT** | PM & Orchestrator |
| `/plan` | **NEXUS-PLAN** | Requirements & Stories |
| `/arch` | **NEXUS-ARCH** | System Architecture |
| `/code` | **NEXUS-CODE** | Implementation (Generates Files) |
| `/test` | **NEXUS-TEST** | QA & Testing |
| `/sec` | **NEXUS-SEC** | Security Audit |
| `/ops` | **NEXUS-OPS** | DevOps & CI/CD |

## ü§ù Contributing

NexusFlow is an open-source project dedicated to pushing the boundaries of AI-assisted development. The Ollama integration represents a significant leap forward in local AI accessibility and dependency management.

### How to Contribute
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Contact & Acknowledgments
- **Project Maintainer**: [dream.pixels.forge@gmail.com](mailto:dream.pixels.forge@gmail.com)
- **Open Source Vision**: This project aims to democratize access to advanced AI development tools
- **Special Thanks**: To all contributors who believe in the power of local-first AI solutions

### ‚≠ê Support the Project
If you find NexusFlow valuable, please consider giving it a star on GitHub! Your support helps grow the community and drive further development of innovative AI development tools.
